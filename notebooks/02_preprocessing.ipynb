{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63fddbf",
   "metadata": {},
   "source": [
    "# Data Preprocessing - Amazon Beauty Products Recommendation System\n",
    "\n",
    "**Mục tiêu:** Chuẩn bị dữ liệu cho recommendation system\n",
    "\n",
    "## Nội dung:\n",
    "- Xử lý missing values và outliers\n",
    "- Validate và clean dữ liệu\n",
    "- Feature engineering cho recommendation\n",
    "- Normalization và standardization\n",
    "- Xử lý numerical stability\n",
    "- Tạo user-item matrix\n",
    "- Split data cho training/validation/testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57874653",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a90130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "# Constants for numerical stability\n",
    "EPSILON = 1e-10\n",
    "\n",
    "print(\"✓ Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee60d32",
   "metadata": {},
   "source": [
    "## 2. Load Raw Data\n",
    "\n",
    "Load dữ liệu từ file CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bb6bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load data using NumPy (reuse từ notebook 01)\n",
    "data_path = '../data/raw/ratings_Beauty.csv'\n",
    "\n",
    "print(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e511885",
   "metadata": {},
   "source": [
    "## 3. Data Validation\n",
    "\n",
    "Kiểm tra tính hợp lệ của dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cc6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validate data\n",
    "# 1. Check rating range (should be 1-5 or 0-5)\n",
    "# 2. Check for invalid user IDs\n",
    "# 3. Check for invalid product IDs\n",
    "# 4. Check timestamp validity (if available)\n",
    "# 5. Remove duplicate entries (same user, same product, same timestamp)\n",
    "\n",
    "# Example validation:\n",
    "# valid_ratings = (ratings >= 1) & (ratings <= 5)\n",
    "# data = data[valid_ratings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad577930",
   "metadata": {},
   "source": [
    "## 4. Handle Missing Values\n",
    "\n",
    "Xử lý giá trị thiếu (nếu có)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce4302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Handle missing values\n",
    "# Strategy for ratings data:\n",
    "# 1. Remove rows with missing UserId or ProductId (critical)\n",
    "# 2. Fill missing ratings với median rating (if any)\n",
    "# 3. Handle missing timestamps (if any)\n",
    "\n",
    "# Note: Rating data thường ít missing values\n",
    "# Nhưng nếu có, cần xử lý cẩn thận để không ảnh hưởng recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3b70b",
   "metadata": {},
   "source": [
    "## 5. Outlier Detection and Treatment\n",
    "\n",
    "Phát hiện và xử lý outliers trong ratings behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365fdc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Detect outliers\n",
    "# For recommendation systems, outliers might be:\n",
    "# 1. Users với số lượng ratings quá cao (bots, professional reviewers)\n",
    "# 2. Products với số ratings bất thường\n",
    "# 3. Suspicious rating patterns (all 5-star or all 1-star from one user)\n",
    "\n",
    "# Detection methods:\n",
    "# - IQR method for ratings count per user/product\n",
    "# - Z-score for abnormal rating patterns\n",
    "# - Statistical tests for suspicious behavior\n",
    "\n",
    "# Treatment: \n",
    "# - Can keep them but flag for separate analysis\n",
    "# - Or filter out extreme cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5cb8a5",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering\n",
    "\n",
    "Tạo features mới để cải thiện recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b08d5df",
   "metadata": {},
   "source": [
    "### 6.1. User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b08631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create user-based features using NumPy\n",
    "# 1. user_avg_rating: Average rating per user (user bias)\n",
    "# 2. user_rating_count: Total ratings per user\n",
    "# 3. user_rating_std: Rating variance per user\n",
    "# 4. user_activity_level: Categorize users (low/medium/high activity)\n",
    "# 5. user_rating_range: max - min rating per user\n",
    "\n",
    "# Use np.unique() và broadcasting để calculate efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe5871",
   "metadata": {},
   "source": [
    "### 6.2. Product Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d252a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create product-based features\n",
    "# 1. product_avg_rating: Average rating per product\n",
    "# 2. product_rating_count: Number of ratings per product (popularity)\n",
    "# 3. product_rating_std: Rating variance (controversy score)\n",
    "# 4. product_weighted_rating: Bayesian average\n",
    "# 5. product_popularity_tier: Categorize products\n",
    "\n",
    "# Bayesian average formula:\n",
    "# weighted_rating = (v/(v+m)) * R + (m/(v+m)) * C\n",
    "# v = ratings count, m = min threshold, R = product avg, C = global avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac1f500",
   "metadata": {},
   "source": [
    "### 6.3. Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5031aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create user-product interaction features\n",
    "# 1. rating_deviation_user: rating - user_avg_rating\n",
    "# 2. rating_deviation_product: rating - product_avg_rating\n",
    "# 3. rating_deviation_global: rating - global_avg_rating\n",
    "# 4. normalized_rating: (rating - user_avg) / user_std\n",
    "\n",
    "# These features help remove biases:\n",
    "# - Some users always rate high/low\n",
    "# - Some products are generally rated high/low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25d041",
   "metadata": {},
   "source": [
    "### 6.4. Temporal Features (if timestamp available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create temporal features (if timestamp available)\n",
    "# 1. days_since_first_rating: User tenure\n",
    "# 2. rating_recency: How recent is the rating\n",
    "# 3. user_rating_velocity: Ratings per day/week\n",
    "# 4. temporal_weights: Weight recent ratings more\n",
    "\n",
    "# Recent ratings might be more relevant for recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7aee8",
   "metadata": {},
   "source": [
    "## 7. Data Normalization & Standardization\n",
    "\n",
    "Chuẩn hóa features để cải thiện model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80475eda",
   "metadata": {},
   "source": [
    "### 7.1. Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Min-Max Normalization\n",
    "def min_max_normalize(x, x_min=None, x_max=None):\n",
    "    \"\"\"\n",
    "    Normalize to [0, 1] range\n",
    "    Formula: (x - min) / (max - min)\n",
    "    \"\"\"\n",
    "    if x_min is None:\n",
    "        x_min = np.min(x)\n",
    "    if x_max is None:\n",
    "        x_max = np.max(x)\n",
    "    \n",
    "    # Numerical stability: avoid division by zero\n",
    "    denominator = x_max - x_min\n",
    "    if denominator == 0:\n",
    "        return np.zeros_like(x)\n",
    "    \n",
    "    return (x - x_min) / (denominator + EPSILON)\n",
    "\n",
    "# Apply to features like rating counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc999e9",
   "metadata": {},
   "source": [
    "### 7.2. Z-score Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb5d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Z-score Standardization\n",
    "def standardize(x, mean=None, std=None):\n",
    "    \"\"\"\n",
    "    Standardize to mean=0, std=1\n",
    "    Formula: (x - mean) / std\n",
    "    \"\"\"\n",
    "    if mean is None:\n",
    "        mean = np.mean(x)\n",
    "    if std is None:\n",
    "        std = np.std(x)\n",
    "    \n",
    "    # Numerical stability\n",
    "    if std == 0:\n",
    "        return np.zeros_like(x)\n",
    "    \n",
    "    return (x - mean) / (std + EPSILON)\n",
    "\n",
    "# Important for gradient-based algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d37593",
   "metadata": {},
   "source": [
    "### 7.3. Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Log Transformation\n",
    "def log_transform(x, constant=1):\n",
    "    \"\"\"\n",
    "    Log transformation for skewed distributions\n",
    "    Formula: log(x + constant)\n",
    "    \"\"\"\n",
    "    # Ensure positive values\n",
    "    x_positive = np.clip(x, 0, None) + constant\n",
    "    return np.log(x_positive + EPSILON)\n",
    "\n",
    "# Useful for:\n",
    "# - Rating counts (often power-law distributed)\n",
    "# - Popularity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96a9b7",
   "metadata": {},
   "source": [
    "## 8. Numerical Stability Techniques\n",
    "\n",
    "Đảm bảo tính ổn định trong tính toán số học"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical stability functions\n",
    "\n",
    "def safe_divide(numerator, denominator, epsilon=EPSILON):\n",
    "    \"\"\"Safe division avoiding division by zero\"\"\"\n",
    "    return numerator / (denominator + epsilon)\n",
    "\n",
    "def safe_log(x, epsilon=EPSILON):\n",
    "    \"\"\"Safe logarithm\"\"\"\n",
    "    return np.log(np.clip(x, epsilon, None))\n",
    "\n",
    "def safe_sqrt(x, epsilon=EPSILON):\n",
    "    \"\"\"Safe square root\"\"\"\n",
    "    return np.sqrt(np.clip(x, epsilon, None))\n",
    "\n",
    "def clip_values(x, min_val, max_val):\n",
    "    \"\"\"Clip values to prevent overflow/underflow\"\"\"\n",
    "    return np.clip(x, min_val, max_val)\n",
    "\n",
    "# Use these functions throughout preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1bfb7c",
   "metadata": {},
   "source": [
    "## 9. User-Item Matrix Construction\n",
    "\n",
    "Tạo user-item rating matrix - core structure cho recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create user-item matrix using NumPy\n",
    "\n",
    "def create_user_item_matrix(user_ids, product_ids, ratings):\n",
    "    \"\"\"\n",
    "    Create user-item rating matrix\n",
    "    \n",
    "    Returns:\n",
    "    - matrix: (n_users, n_products) array\n",
    "    - user_mapping: dict {user_id: index}\n",
    "    - product_mapping: dict {product_id: index}\n",
    "    \"\"\"\n",
    "    # Get unique IDs\n",
    "    unique_users = np.unique(user_ids)\n",
    "    unique_products = np.unique(product_ids)\n",
    "    \n",
    "    # Create mappings\n",
    "    user_to_idx = {user: idx for idx, user in enumerate(unique_users)}\n",
    "    product_to_idx = {prod: idx for idx, prod in enumerate(unique_products)}\n",
    "    \n",
    "    # Initialize matrix with zeros (or NaN for missing values)\n",
    "    n_users = len(unique_users)\n",
    "    n_products = len(unique_products)\n",
    "    matrix = np.zeros((n_users, n_products))\n",
    "    \n",
    "    # Fill matrix using vectorization\n",
    "    # TODO: Implement efficient filling\n",
    "    \n",
    "    return matrix, user_to_idx, product_to_idx\n",
    "\n",
    "# Calculate sparsity\n",
    "# sparsity = 1 - (nnz / total_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d6bbff",
   "metadata": {},
   "source": [
    "## 10. Handle Cold Start Problem\n",
    "\n",
    "Xử lý users/products với ít data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Filter or handle cold start items\n",
    "# Strategy 1: Filter out users/products với < threshold ratings\n",
    "min_user_ratings = 5  # Minimum ratings per user\n",
    "min_product_ratings = 5  # Minimum ratings per product\n",
    "\n",
    "# Strategy 2: Keep them but use different recommendation approach\n",
    "# - Popularity-based for new users\n",
    "# - Content-based for new products\n",
    "# - Use global statistics\n",
    "\n",
    "# Note: Balance between data quality và dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fa8b84",
   "metadata": {},
   "source": [
    "## 11. Data Splitting\n",
    "\n",
    "Chia dữ liệu cho training, validation, và testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfaf4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split data using NumPy\n",
    "def train_val_test_split(data, train_ratio=0.7, val_ratio=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data into train/val/test sets\n",
    "    \n",
    "    Important: For recommendation systems, consider:\n",
    "    1. Random split: Random selection of ratings\n",
    "    2. Temporal split: Split by time (if timestamp available)\n",
    "    3. User-based split: Some users in train, others in test\n",
    "    4. Leave-one-out: Hold out one rating per user for testing\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n_samples = len(data)\n",
    "    \n",
    "    # Shuffle indices\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    \n",
    "    # Calculate split points\n",
    "    train_end = int(train_ratio * n_samples)\n",
    "    val_end = int((train_ratio + val_ratio) * n_samples)\n",
    "    \n",
    "    # Split\n",
    "    train_idx = indices[:train_end]\n",
    "    val_idx = indices[train_end:val_end]\n",
    "    test_idx = indices[val_end:]\n",
    "    \n",
    "    return train_idx, val_idx, test_idx\n",
    "\n",
    "# Important: Avoid data leakage!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759b0e4e",
   "metadata": {},
   "source": [
    "## 12. Statistical Hypothesis Testing\n",
    "\n",
    "Kiểm định các giả thiết thống kê về dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd11217",
   "metadata": {},
   "source": [
    "### Test 1: Rating distribution normality\n",
    "\n",
    "**H0:** Rating distribution follows normal distribution  \n",
    "**H1:** Rating distribution does not follow normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca537159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test for normality\n",
    "# Use Q-Q plot visualization\n",
    "# Calculate skewness and kurtosis\n",
    "# Interpretation will guide choice of transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cb335",
   "metadata": {},
   "source": [
    "### Test 2: User rating independence\n",
    "\n",
    "**H0:** User ratings are independent  \n",
    "**H1:** User ratings are correlated (e.g., user tends to rate similarly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b237aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test for independence\n",
    "# Calculate intra-user correlation\n",
    "# This helps understand if user bias adjustment is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d950a1d",
   "metadata": {},
   "source": [
    "## 13. Save Processed Data\n",
    "\n",
    "Lưu dữ liệu đã xử lý để sử dụng cho modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save processed data\n",
    "output_dir = '../data/processed/'\n",
    "\n",
    "# Save:\n",
    "# 1. Train/val/test splits (as .npy files)\n",
    "# 2. User-item matrix\n",
    "# 3. User/product mappings (as .npy or pickle)\n",
    "# 4. Feature arrays\n",
    "# 5. Preprocessing parameters (for applying to new data)\n",
    "\n",
    "# Example:\n",
    "# np.save(f'{output_dir}train_data.npy', train_data)\n",
    "# np.save(f'{output_dir}user_item_matrix.npy', user_item_matrix)\n",
    "# np.save(f'{output_dir}user_features.npy', user_features)\n",
    "\n",
    "print(f\"✓ Data saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c81b91",
   "metadata": {},
   "source": [
    "## 14. Preprocessing Summary\n",
    "\n",
    "Tổng kết quá trình preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d023846f",
   "metadata": {},
   "source": [
    "### Preprocessing Steps Completed:\n",
    "\n",
    "**Data Cleaning:**\n",
    "- TODO: Document validation results\n",
    "- TODO: Missing values handling\n",
    "- TODO: Outlier treatment\n",
    "\n",
    "**Feature Engineering:**\n",
    "- TODO: List new features created\n",
    "- TODO: User features\n",
    "- TODO: Product features\n",
    "- TODO: Interaction features\n",
    "\n",
    "**Data Transformation:**\n",
    "- TODO: Normalization applied\n",
    "- TODO: Standardization applied\n",
    "- TODO: Log transforms\n",
    "\n",
    "**Data Structure:**\n",
    "- TODO: User-item matrix dimensions\n",
    "- TODO: Sparsity level\n",
    "- TODO: Train/val/test sizes\n",
    "\n",
    "**Ready for Modeling:**\n",
    "- ✓ Clean data\n",
    "- ✓ Engineered features\n",
    "- ✓ Normalized/standardized\n",
    "- ✓ Train/val/test splits\n",
    "- ✓ Data saved"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
