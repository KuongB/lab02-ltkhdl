{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3568e65d",
   "metadata": {},
   "source": [
    "# Modeling - Amazon Beauty Products Recommendation System\n",
    "\n",
    "**Mục tiêu:** Xây dựng recommendation system từ đầu bằng NumPy\n",
    "\n",
    "## Approaches:\n",
    "1. **Baseline Models:** Mean ratings, popularity-based\n",
    "2. **Collaborative Filtering:** User-based và Item-based\n",
    "3. **Matrix Factorization:** SVD implementation\n",
    "4. **Advanced (Optional):** Hybrid approaches\n",
    "\n",
    "## Evaluation Metrics:\n",
    "- RMSE (Root Mean Squared Error)\n",
    "- MAE (Mean Absolute Error)\n",
    "- Precision@K, Recall@K\n",
    "- NDCG (Normalized Discounted Cumulative Gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d4a5e5",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from time import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "EPSILON = 1e-10\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4264ecc1",
   "metadata": {},
   "source": [
    "## 2. Load Processed Data\n",
    "\n",
    "Load dữ liệu đã được xử lý từ notebook 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load processed data\n",
    "# train_data = np.load('../data/processed/train_data.npy')\n",
    "# val_data = np.load('../data/processed/val_data.npy')\n",
    "# test_data = np.load('../data/processed/test_data.npy')\n",
    "# user_item_matrix = np.load('../data/processed/user_item_matrix.npy')\n",
    "\n",
    "print(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f1579",
   "metadata": {},
   "source": [
    "## 3. Evaluation Metrics\n",
    "\n",
    "Implement các metrics để đánh giá recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement evaluation metrics using NumPy\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Root Mean Squared Error\n",
    "    Formula: sqrt(mean((y_true - y_pred)^2))\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Mean Absolute Error\n",
    "    Formula: mean(|y_true - y_pred|)\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def precision_at_k(y_true, y_pred, k=10, threshold=4.0):\n",
    "    \"\"\"\n",
    "    Precision@K: Proportion of recommended items that are relevant\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    pass\n",
    "\n",
    "def recall_at_k(y_true, y_pred, k=10, threshold=4.0):\n",
    "    \"\"\"\n",
    "    Recall@K: Proportion of relevant items that are recommended\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    pass\n",
    "\n",
    "def ndcg_at_k(y_true, y_pred, k=10):\n",
    "    \"\"\"\n",
    "    Normalized Discounted Cumulative Gain\n",
    "    Measures ranking quality\n",
    "    \"\"\"\n",
    "    # TODO: Implement DCG và IDCG\n",
    "    pass\n",
    "\n",
    "print(\"✓ Metrics implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374c605",
   "metadata": {},
   "source": [
    "## 4. Baseline Models\n",
    "\n",
    "Implement các baseline models đơn giản"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095e4bed",
   "metadata": {},
   "source": [
    "### 4.1. Global Mean Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d99933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Global mean baseline - predict mean rating for all\n",
    "global_mean = np.mean(train_data[:, 2])  # Column 2: ratings\n",
    "baseline_pred = np.full(len(test_data), global_mean)\n",
    "\n",
    "# Evaluate\n",
    "# rmse_baseline = rmse(test_data[:, 2], baseline_pred)\n",
    "# print(f\"Global Mean RMSE: {rmse_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb73f7",
   "metadata": {},
   "source": [
    "### 4.2. User Mean Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ee6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: User mean baseline - predict user's average rating\n",
    "# Calculate mean rating per user\n",
    "# For each test case, predict user's mean rating\n",
    "# If user is new, use global mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f2f0e",
   "metadata": {},
   "source": [
    "### 4.3. Item Mean Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a615906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Item mean baseline - predict product's average rating\n",
    "# Calculate mean rating per product\n",
    "# For each test case, predict product's mean rating\n",
    "# If product is new, use global mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac26bc",
   "metadata": {},
   "source": [
    "### 4.4. Bias-Based Baseline\n",
    "\n",
    "Combining user và item biases:  \n",
    "**Prediction = μ + b_u + b_i**\n",
    "\n",
    "Where:\n",
    "- μ = global mean\n",
    "- b_u = user bias (user_mean - global_mean)\n",
    "- b_i = item bias (item_mean - global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f8b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement bias-based baseline\n",
    "# 1. Calculate global mean\n",
    "# 2. Calculate user biases\n",
    "# 3. Calculate item biases\n",
    "# 4. Predict: μ + b_u + b_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfaf661",
   "metadata": {},
   "source": [
    "## 5. Collaborative Filtering - User-Based\n",
    "\n",
    "User-based CF: Recommend dựa trên similar users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e87c9c",
   "metadata": {},
   "source": [
    "### 5.1. User Similarity Calculation\n",
    "\n",
    "**Cosine Similarity:**  \n",
    "$$\\text{sim}(u, v) = \\frac{\\sum_i r_{ui} \\cdot r_{vi}}{\\sqrt{\\sum_i r_{ui}^2} \\cdot \\sqrt{\\sum_i r_{vi}^2}}$$\n",
    "\n",
    "**Pearson Correlation:**  \n",
    "$$\\text{sim}(u, v) = \\frac{\\sum_i (r_{ui} - \\bar{r}_u)(r_{vi} - \\bar{r}_v)}{\\sqrt{\\sum_i (r_{ui} - \\bar{r}_u)^2} \\cdot \\sqrt{\\sum_i (r_{vi} - \\bar{r}_v)^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement similarity calculations using NumPy\n",
    "\n",
    "def cosine_similarity(matrix):\n",
    "    \"\"\"\n",
    "    Calculate pairwise cosine similarity between rows (users)\n",
    "    Uses vectorization with np.dot() and broadcasting\n",
    "    \"\"\"\n",
    "    # Normalize rows\n",
    "    norms = np.sqrt(np.sum(matrix ** 2, axis=1, keepdims=True))\n",
    "    normalized = matrix / (norms + EPSILON)\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    similarity = np.dot(normalized, normalized.T)\n",
    "    return similarity\n",
    "\n",
    "def pearson_correlation(matrix):\n",
    "    \"\"\"\n",
    "    Calculate pairwise Pearson correlation between rows (users)\n",
    "    \"\"\"\n",
    "    # Center by subtracting mean\n",
    "    mean_centered = matrix - np.mean(matrix, axis=1, keepdims=True)\n",
    "    \n",
    "    # Calculate correlation\n",
    "    norms = np.sqrt(np.sum(mean_centered ** 2, axis=1, keepdims=True))\n",
    "    normalized = mean_centered / (norms + EPSILON)\n",
    "    correlation = np.dot(normalized, normalized.T)\n",
    "    \n",
    "    return correlation\n",
    "\n",
    "# Compute user similarity matrix\n",
    "# user_similarity = cosine_similarity(user_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b175aaa",
   "metadata": {},
   "source": [
    "### 5.2. User-Based Prediction\n",
    "\n",
    "**Prediction formula:**  \n",
    "$$\\hat{r}_{ui} = \\bar{r}_u + \\frac{\\sum_{v \\in N(u)} \\text{sim}(u,v) \\cdot (r_{vi} - \\bar{r}_v)}{\\sum_{v \\in N(u)} |\\text{sim}(u,v)|}$$\n",
    "\n",
    "Where N(u) = k most similar users who rated item i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9205ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement user-based CF prediction\n",
    "\n",
    "class UserBasedCF:\n",
    "    def __init__(self, k=20, similarity='cosine'):\n",
    "        \"\"\"\n",
    "        k: number of similar users to consider\n",
    "        similarity: 'cosine' or 'pearson'\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.similarity = similarity\n",
    "        self.user_similarity = None\n",
    "        self.user_means = None\n",
    "    \n",
    "    def fit(self, user_item_matrix):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        # Calculate similarity\n",
    "        if self.similarity == 'cosine':\n",
    "            self.user_similarity = cosine_similarity(user_item_matrix)\n",
    "        else:\n",
    "            self.user_similarity = pearson_correlation(user_item_matrix)\n",
    "        \n",
    "        # Calculate user means\n",
    "        # Handle zeros (non-rated items)\n",
    "        # TODO: Implement\n",
    "        pass\n",
    "    \n",
    "    def predict(self, user_id, item_id):\n",
    "        \"\"\"Predict rating for a user-item pair\"\"\"\n",
    "        # Find k most similar users who rated this item\n",
    "        # Weighted average of their ratings\n",
    "        # TODO: Implement using NumPy\n",
    "        pass\n",
    "    \n",
    "    def recommend(self, user_id, n=10):\n",
    "        \"\"\"Recommend top-n items for a user\"\"\"\n",
    "        # Predict for all unrated items\n",
    "        # Return top-n highest predictions\n",
    "        # TODO: Implement\n",
    "        pass\n",
    "\n",
    "# Train and evaluate\n",
    "# model = UserBasedCF(k=20)\n",
    "# model.fit(user_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ce3e6",
   "metadata": {},
   "source": [
    "## 6. Collaborative Filtering - Item-Based\n",
    "\n",
    "Item-based CF: Recommend dựa trên similar items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d1ac8a",
   "metadata": {},
   "source": [
    "### 6.1. Item Similarity\n",
    "\n",
    "Calculate similarity between items (products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb6c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate item similarity\n",
    "# Transpose user-item matrix để get item-user matrix\n",
    "# item_item_matrix = user_item_matrix.T\n",
    "# item_similarity = cosine_similarity(item_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d948a",
   "metadata": {},
   "source": [
    "### 6.2. Item-Based Prediction\n",
    "\n",
    "**Prediction formula:**  \n",
    "$$\\hat{r}_{ui} = \\frac{\\sum_{j \\in N(i)} \\text{sim}(i,j) \\cdot r_{uj}}{\\sum_{j \\in N(i)} |\\text{sim}(i,j)|}$$\n",
    "\n",
    "Where N(i) = k most similar items rated by user u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e679079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement item-based CF\n",
    "\n",
    "class ItemBasedCF:\n",
    "    def __init__(self, k=20, similarity='cosine'):\n",
    "        self.k = k\n",
    "        self.similarity = similarity\n",
    "        self.item_similarity = None\n",
    "    \n",
    "    def fit(self, user_item_matrix):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        # Calculate item-item similarity\n",
    "        # TODO: Implement\n",
    "        pass\n",
    "    \n",
    "    def predict(self, user_id, item_id):\n",
    "        \"\"\"Predict rating\"\"\"\n",
    "        # Find k most similar items rated by user\n",
    "        # Weighted average\n",
    "        # TODO: Implement\n",
    "        pass\n",
    "    \n",
    "    def recommend(self, user_id, n=10):\n",
    "        \"\"\"Recommend top-n items\"\"\"\n",
    "        # TODO: Implement\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043568a",
   "metadata": {},
   "source": [
    "## 7. Matrix Factorization (SVD)\n",
    "\n",
    "Implement SVD từ đầu bằng NumPy - **BONUS POINTS!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a23ed1",
   "metadata": {},
   "source": [
    "### 7.1. SVD Basics\n",
    "\n",
    "**Matrix Factorization:** R ≈ U × Σ × V^T\n",
    "\n",
    "Where:\n",
    "- R: user-item matrix (m × n)\n",
    "- U: user features (m × k)\n",
    "- Σ: singular values (k × k)\n",
    "- V: item features (n × k)\n",
    "- k: number of latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4fadda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement SVD using NumPy\n",
    "\n",
    "def svd_decomposition(matrix, k=20):\n",
    "    \"\"\"\n",
    "    Perform SVD decomposition using NumPy's linalg.svd\n",
    "    \"\"\"\n",
    "    # Use numpy's SVD\n",
    "    U, sigma, Vt = np.linalg.svd(matrix, full_matrices=False)\n",
    "    \n",
    "    # Keep only top k factors\n",
    "    U_k = U[:, :k]\n",
    "    sigma_k = sigma[:k]\n",
    "    Vt_k = Vt[:k, :]\n",
    "    \n",
    "    # Reconstruct approximated matrix\n",
    "    matrix_approx = U_k @ np.diag(sigma_k) @ Vt_k\n",
    "    \n",
    "    return U_k, sigma_k, Vt_k, matrix_approx\n",
    "\n",
    "# Apply SVD\n",
    "# U, sigma, Vt, R_approx = svd_decomposition(user_item_matrix, k=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c6d41",
   "metadata": {},
   "source": [
    "### 7.2. Gradient Descent for Matrix Factorization\n",
    "\n",
    "Optimize bằng gradient descent - **ADVANCED BONUS!**\n",
    "\n",
    "**Loss Function:**  \n",
    "$$L = \\sum_{(u,i) \\in \\text{observed}} (r_{ui} - p_u \\cdot q_i^T)^2 + \\lambda(||p_u||^2 + ||q_i||^2)$$\n",
    "\n",
    "**Gradients:**  \n",
    "$$\\frac{\\partial L}{\\partial p_u} = -2(r_{ui} - \\hat{r}_{ui})q_i + 2\\lambda p_u$$  \n",
    "$$\\frac{\\partial L}{\\partial q_i} = -2(r_{ui} - \\hat{r}_{ui})p_u + 2\\lambda q_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42c4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Matrix Factorization with SGD\n",
    "\n",
    "class MatrixFactorization:\n",
    "    def __init__(self, n_factors=20, learning_rate=0.01, reg=0.02, n_epochs=20):\n",
    "        \"\"\"\n",
    "        n_factors: number of latent factors (k)\n",
    "        learning_rate: α for gradient descent\n",
    "        reg: λ for regularization\n",
    "        n_epochs: number of training iterations\n",
    "        \"\"\"\n",
    "        self.n_factors = n_factors\n",
    "        self.lr = learning_rate\n",
    "        self.reg = reg\n",
    "        self.n_epochs = n_epochs\n",
    "        self.user_factors = None  # P matrix\n",
    "        self.item_factors = None  # Q matrix\n",
    "        self.user_bias = None\n",
    "        self.item_bias = None\n",
    "        self.global_mean = None\n",
    "    \n",
    "    def fit(self, train_data):\n",
    "        \"\"\"\n",
    "        Train using Stochastic Gradient Descent\n",
    "        train_data: array of (user_id, item_id, rating)\n",
    "        \"\"\"\n",
    "        # Initialize parameters\n",
    "        n_users = int(np.max(train_data[:, 0])) + 1\n",
    "        n_items = int(np.max(train_data[:, 1])) + 1\n",
    "        \n",
    "        # Random initialization\n",
    "        self.user_factors = np.random.normal(0, 0.1, (n_users, self.n_factors))\n",
    "        self.item_factors = np.random.normal(0, 0.1, (n_items, self.n_factors))\n",
    "        self.user_bias = np.zeros(n_users)\n",
    "        self.item_bias = np.zeros(n_items)\n",
    "        self.global_mean = np.mean(train_data[:, 2])\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(self.n_epochs):\n",
    "            # Shuffle data\n",
    "            np.random.shuffle(train_data)\n",
    "            \n",
    "            # SGD updates\n",
    "            for user_id, item_id, rating in train_data:\n",
    "                user_id = int(user_id)\n",
    "                item_id = int(item_id)\n",
    "                \n",
    "                # Predict\n",
    "                pred = self.predict(user_id, item_id)\n",
    "                error = rating - pred\n",
    "                \n",
    "                # Update user factors\n",
    "                self.user_factors[user_id] += self.lr * (\n",
    "                    error * self.item_factors[item_id] - \n",
    "                    self.reg * self.user_factors[user_id]\n",
    "                )\n",
    "                \n",
    "                # Update item factors\n",
    "                self.item_factors[item_id] += self.lr * (\n",
    "                    error * self.user_factors[user_id] -\n",
    "                    self.reg * self.item_factors[item_id]\n",
    "                )\n",
    "                \n",
    "                # Update biases\n",
    "                self.user_bias[user_id] += self.lr * (error - self.reg * self.user_bias[user_id])\n",
    "                self.item_bias[item_id] += self.lr * (error - self.reg * self.item_bias[item_id])\n",
    "            \n",
    "            # TODO: Calculate and print training RMSE\n",
    "            # if epoch % 5 == 0:\n",
    "            #     train_rmse = self.evaluate(train_data)\n",
    "            #     print(f\"Epoch {epoch}: RMSE = {train_rmse:.4f}\")\n",
    "    \n",
    "    def predict(self, user_id, item_id):\n",
    "        \"\"\"Predict rating for user-item pair\"\"\"\n",
    "        pred = (\n",
    "            self.global_mean +\n",
    "            self.user_bias[user_id] +\n",
    "            self.item_bias[item_id] +\n",
    "            np.dot(self.user_factors[user_id], self.item_factors[item_id])\n",
    "        )\n",
    "        return pred\n",
    "    \n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Evaluate on test data\"\"\"\n",
    "        predictions = []\n",
    "        for user_id, item_id, _ in test_data:\n",
    "            pred = self.predict(int(user_id), int(item_id))\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        return rmse(test_data[:, 2], np.array(predictions))\n",
    "\n",
    "# Train model\n",
    "# mf = MatrixFactorization(n_factors=50, learning_rate=0.01, reg=0.02, n_epochs=20)\n",
    "# mf.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aa68b6",
   "metadata": {},
   "source": [
    "## 8. Model Comparison\n",
    "\n",
    "So sánh performance của các models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85858e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare all models\n",
    "# Create comparison table và visualization\n",
    "\n",
    "models_results = {\n",
    "    'Model': [],\n",
    "    'RMSE': [],\n",
    "    'MAE': [],\n",
    "    'Training Time (s)': []\n",
    "}\n",
    "\n",
    "# Example:\n",
    "# models_results['Model'].append('Global Mean')\n",
    "# models_results['RMSE'].append(rmse_baseline)\n",
    "# ...\n",
    "\n",
    "# Visualize comparison\n",
    "# Bar chart showing RMSE for each model\n",
    "# Training time comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e0c135",
   "metadata": {},
   "source": [
    "## 9. Hyperparameter Tuning\n",
    "\n",
    "Tối ưu hyperparameters cho model tốt nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2f331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement grid search or random search using NumPy\n",
    "# For example, tune Matrix Factorization:\n",
    "# - n_factors: [10, 20, 50, 100]\n",
    "# - learning_rate: [0.001, 0.01, 0.05]\n",
    "# - regularization: [0.01, 0.02, 0.05]\n",
    "\n",
    "def grid_search(param_grid, train_data, val_data):\n",
    "    \"\"\"\n",
    "    Simple grid search implementation\n",
    "    \"\"\"\n",
    "    best_params = None\n",
    "    best_rmse = float('inf')\n",
    "    \n",
    "    # TODO: Iterate through all parameter combinations\n",
    "    # Train model và evaluate on validation set\n",
    "    # Keep track of best parameters\n",
    "    \n",
    "    return best_params, best_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07f75f",
   "metadata": {},
   "source": [
    "## 10. Final Evaluation on Test Set\n",
    "\n",
    "Đánh giá model tốt nhất trên test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d83121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Final evaluation\n",
    "# Use best model on test set\n",
    "# Calculate all metrics:\n",
    "# - RMSE, MAE\n",
    "# - Precision@K, Recall@K\n",
    "# - NDCG@K\n",
    "\n",
    "# Visualize:\n",
    "# - Prediction vs Actual scatter plot\n",
    "# - Error distribution\n",
    "# - Top-N recommendations for sample users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c8b73",
   "metadata": {},
   "source": [
    "## 11. Recommendation Examples\n",
    "\n",
    "Demonstrate recommendations cho specific users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7498bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Show recommendations for sample users\n",
    "# Select 5 users\n",
    "# For each user:\n",
    "# 1. Show their rating history\n",
    "# 2. Show top-10 recommendations\n",
    "# 3. Explain why (similar users/items, predicted ratings)\n",
    "\n",
    "# Example:\n",
    "# user_id = 123\n",
    "# user_history = get_user_history(user_id)\n",
    "# recommendations = model.recommend(user_id, n=10)\n",
    "# print(f\"User {user_id} rated {len(user_history)} products\")\n",
    "# print(f\"Top 10 recommendations: {recommendations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb91bfa",
   "metadata": {},
   "source": [
    "## 12. Model Analysis & Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee365b",
   "metadata": {},
   "source": [
    "### 12.1. Learned Latent Factors\n",
    "\n",
    "Phân tích các latent factors từ Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c462a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze latent factors\n",
    "# - Visualize user/item factors (dimensionality reduction to 2D)\n",
    "# - Find similar users in latent space\n",
    "# - Find similar items in latent space\n",
    "# - Interpret factors (if possible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da0bda",
   "metadata": {},
   "source": [
    "### 12.2. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3059d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze prediction errors\n",
    "# - Which users are hardest to predict?\n",
    "# - Which items are hardest to predict?\n",
    "# - Relationship between error và:\n",
    "#   * Number of ratings\n",
    "#   * Rating variance\n",
    "#   * User/item popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7292abf6",
   "metadata": {},
   "source": [
    "## 13. Summary & Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b6dd2b",
   "metadata": {},
   "source": [
    "### Key Findings:\n",
    "\n",
    "**Model Performance:**\n",
    "- TODO: Best performing model và metrics\n",
    "- TODO: Comparison với baselines\n",
    "- TODO: Trade-offs (accuracy vs speed)\n",
    "\n",
    "**Recommendation Quality:**\n",
    "- TODO: Diversity of recommendations\n",
    "- TODO: Coverage (% of items recommended)\n",
    "- TODO: Cold start handling\n",
    "\n",
    "**Implementation:**\n",
    "- TODO: NumPy techniques used (vectorization, broadcasting, etc.)\n",
    "- TODO: Numerical stability considerations\n",
    "- TODO: Computational efficiency\n",
    "\n",
    "**Business Insights:**\n",
    "- TODO: Most recommended products\n",
    "- TODO: User segments with different preferences\n",
    "- TODO: Opportunities for improvement\n",
    "\n",
    "**Limitations:**\n",
    "- TODO: Data sparsity challenges\n",
    "- TODO: Cold start problem\n",
    "- TODO: Scalability considerations\n",
    "\n",
    "**Future Improvements:**\n",
    "- TODO: Content-based features\n",
    "- TODO: Hybrid approaches\n",
    "- TODO: Deep learning methods (if allowed)\n",
    "- TODO: Real-time recommendations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
