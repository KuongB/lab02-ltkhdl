{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 03. Modeling and Evaluation\n",
                "\n",
                "## Objective\n",
                "Implement and compare two models using **NumPy exclusively**:\n",
                "1.  **Model 1 (OLS)**: Ordinary Least Squares Linear Regression.\n",
                "2.  **Model 2 (Lasso)**: Lasso Regression (L1 Regularization) using **Coordinate Descent**.\n",
                "\n",
                "**Evaluation Strategy**:\n",
                "- **Hold-out**: 20% of data reserved for final testing.\n",
                "- **Cross-Validation**: 5-Fold CV on the remaining 80% training data.\n",
                "- **Metrics**: Mean Squared Error (MSE) and $R^2$ Score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Data Loading Complete ---\n",
                        "Data Shape: (48258,)\n",
                        "Column Names: ('latitude', 'longitude', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365', 'price_log', 'neighbourhood_group_Brooklyn', 'neighbourhood_group_Manhattan', 'neighbourhood_group_Queens', 'neighbourhood_group_Staten Island', 'room_type_Private room', 'room_type_Shared room', 'review_activity', 'review_quality_score', 'is_high_value_core', 'interaction_nights_reviews')\n",
                        "\n",
                        "Feature Matrix X Shape: (48258, 17)\n",
                        "Target Vector Y Shape: (48258,)\n",
                        "Features used: ['latitude', 'longitude', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365', 'neighbourhood_group_Brooklyn', 'neighbourhood_group_Manhattan', 'neighbourhood_group_Queens', 'neighbourhood_group_Staten Island', 'room_type_Private room', 'room_type_Shared room', 'review_activity', 'review_quality_score', 'is_high_value_core', 'interaction_nights_reviews']\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import csv\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "PROCESSED_DATA_PATH = '../data/processed/airbnb_processed.csv'\n",
                "\n",
                "# Update dtype to reflect scaled float64 columns from preprocessing\n",
                "processed_dtype = np.dtype([\n",
                "    ('latitude', np.float64),\n",
                "    ('longitude', np.float64),\n",
                "    ('price', np.int32),           # Original Value\n",
                "    ('minimum_nights', np.float64),\n",
                "    ('number_of_reviews', np.float64),\n",
                "    ('reviews_per_month', np.float64),\n",
                "    ('calculated_host_listings_count', np.float64),\n",
                "    ('availability_365', np.float64),\n",
                "    ('price_log', np.float64),     # Target Variable Y\n",
                "    ('neighbourhood_group_Brooklyn', np.float64),\n",
                "    ('neighbourhood_group_Manhattan', np.float64),\n",
                "    ('neighbourhood_group_Queens', np.float64),\n",
                "    ('neighbourhood_group_Staten Island', np.float64),\n",
                "    ('room_type_Private room', np.float64),\n",
                "    ('room_type_Shared room', np.float64),\n",
                "    ('review_activity', np.float64),\n",
                "    ('review_quality_score', np.float64),\n",
                "    ('is_high_value_core', np.float64),\n",
                "    ('interaction_nights_reviews', np.float64) # New Feature\n",
                "])\n",
                "\n",
                "# --- 2. Data Loading Function (Using csv and NumPy) ---\n",
                "\n",
                "def load_processed_data(file_path, target_dtype):\n",
                "    with open(file_path, mode='r', encoding='utf-8') as f:\n",
                "        reader = csv.reader(f)\n",
                "        header = next(reader) \n",
                "        raw_data = list(reader)\n",
                "    \n",
                "    raw_array = np.array(raw_data, dtype=object)\n",
                "    \n",
                "    N = len(raw_array)\n",
                "    structured_data = np.zeros(N, dtype=target_dtype)\n",
                "    \n",
                "    for i, name in enumerate(target_dtype.names):\n",
                "        column_data = raw_array[:, i]\n",
                "        target_type = target_dtype[name].type\n",
                "        try:\n",
                "            structured_data[name] = column_data.astype(target_type)\n",
                "        except ValueError:\n",
                "            # Fallback for empty strings if any remain\n",
                "            column_data[column_data == ''] = '0'\n",
                "            structured_data[name] = column_data.astype(target_type)\n",
                "            \n",
                "    return header, structured_data\n",
                "\n",
                "header, data = load_processed_data(PROCESSED_DATA_PATH, processed_dtype)\n",
                "\n",
                "print(\"--- Data Loading Complete ---\")\n",
                "print(f\"Data Shape: {data.shape}\")\n",
                "print(f\"Column Names: {data.dtype.names}\")\n",
                "\n",
                "# --- Prepare X (Features) and Y (Target) ---\n",
                "target_col = 'price_log'\n",
                "exclude_cols = {'price', 'price_log'}\n",
                "feature_names = [name for name in data.dtype.names if name not in exclude_cols]\n",
                "\n",
                "Y_all = data[target_col]\n",
                "X_list = [data[name] for name in feature_names]\n",
                "X_all = np.column_stack(X_list)\n",
                "\n",
                "print(f\"\\nFeature Matrix X Shape: {X_all.shape}\")\n",
                "print(f\"Target Vector Y Shape: {Y_all.shape}\")\n",
                "print(f\"Features used: {feature_names}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Splitting\n",
                "We split the data into **Train (80%)** and **Test (20%)** sets using random shuffling.  \n",
                "The 20% independent test set will strictly be used ONLY for the final evaluation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training Set: 38606 samples\n",
                        "Test Set: 9652 samples\n"
                    ]
                }
            ],
            "source": [
                "np.random.seed(77)\n",
                "indices = np.arange(len(X_all))\n",
                "np.random.shuffle(indices)\n",
                "\n",
                "test_size = 0.2\n",
                "split_idx = int(len(X_all) * (1 - test_size))\n",
                "\n",
                "train_indices = indices[:split_idx]\n",
                "test_indices = indices[split_idx:]\n",
                "\n",
                "X_train_full = X_all[train_indices]\n",
                "Y_train = Y_all[train_indices]\n",
                "\n",
                "X_test_full = X_all[test_indices]\n",
                "Y_test = Y_all[test_indices]\n",
                "\n",
                "print(f\"Training Set: {X_train_full.shape[0]} samples\")\n",
                "print(f\"Test Set: {X_test_full.shape[0]} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Models Implementation: Theory & Code\n",
                "\n",
                "### OLS\n",
                "\n",
                "The goal of OLS is to find the parameter vector $W \\in \\mathbb{R}^d$ that minimizes the **Sum of Squared Errors (SSE)** between the true values $Y \\in \\mathbb{R}^n$ and the predicted values $\\hat{Y} = XW$:\n",
                "\n",
                "$$ J(W) = ||Y - XW||^2_2 = \\sum_{i=1}^n (y_i - x_i^T W)^2 $$\n",
                "\n",
                "To find the minimum, we take the gradient with respect to $W$ and set it to zero:\n",
                "\n",
                "$$ \\nabla_W J(W) = \\nabla_W (Y^TY - 2Y^TXW + W^TX^TXW) = -2X^T(Y - XW) = 0 $$\n",
                "\n",
                "Rearranging the terms gives us the **Normal Equation**:\n",
                "\n",
                "$$ X^T X W = X^T Y \\implies W = (X^T X)^{-1} X^T Y $$\n",
                "\n",
                "**NumPy Implementation Note**:\n",
                "Directly computing the inverse $(X^T X)^{-1}$ can be numerically unstable if features are multicollinear. We use `np.linalg.lstsq`, which employs **Singular Value Decomposition (SVD)** to solve the system, offering higher numerical precision and stability.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Feature Preparation ---\n",
                "def add_intercept(X):\n",
                "    intercept = np.ones((X.shape[0], 1))\n",
                "    return np.hstack((intercept, X))\n",
                "\n",
                "# --- Linear Models ---\n",
                "\n",
                "def train_linear_regression(X, Y):\n",
                "    # Uses Normal Equation via SVD (lstsq) for OLS\n",
                "    W, residuals, rank, singular_values = np.linalg.lstsq(X, Y, rcond=None)\n",
                "    return W\n",
                "\n",
                "def predict_linear(X, W):\n",
                "    return X @ W\n",
                "\n",
                "\n",
                "\n",
                "# --- Metrics ---\n",
                "def mse(y_true, y_pred):\n",
                "    return np.mean((y_true - y_pred) ** 2)\n",
                "\n",
                "def r2_score(y_true, y_pred):\n",
                "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
                "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
                "    return 1 - (ss_res / (ss_tot + 1e-8))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. K-Fold Cross Validation: Logic & Implementation\n",
                "\n",
                "**Objective**: To robustly estimate model performance and tune hyperparameters ($\\lambda$) without touching the Test Set.\n",
                "\n",
                "**Logic**:\n",
                "1.  Divide the `X_train_full` data into $k=5$ equal folds.\n",
                "2.  Iterate $i$ from $0$ to $k-1$:\n",
                "    -   **Validation Fold**: Fold $i$.\n",
                "    -   **Training Folds**: All folds except $i$.\n",
                "3.  Train model on Training Folds $\\rightarrow$ Predict on Validation Fold.\n",
                "4.  Average the MSE/R2 scores across all $k$ iterations.\n",
                "\n",
                "**NumPy Implementation Details**:\n",
                "-   We use `np.arange` to generate indices.\n",
                "-   We slice indices `indices[val_start:val_end]` for validation.\n",
                "-   We use `np.concatenate` to merge the remaining indices for training.\n",
                "-   **Note**: We manually add the intercept column inside the loop to ensure clean separation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [],
            "source": [
                "def k_fold_cross_validation(X, Y, model_type='linear', k=5, **kwargs):\n",
                "    \"\"\"\n",
                "    Perform K-Fold CV\n",
                "    X should be passed WITHOUT intercept (Intercept added inside).\n",
                "    \"\"\"\n",
                "    fold_size = len(X) // k\n",
                "    indices = np.arange(len(X))\n",
                "    # Data is already shuffled at start, so sequential chunking is fine\n",
                "    \n",
                "    mse_scores = []\n",
                "    r2_scores = []\n",
                "    \n",
                "    for i in range(k):\n",
                "        val_start = i * fold_size\n",
                "        val_end = (i + 1) * fold_size\n",
                "        \n",
                "        val_idx = indices[val_start:val_end]\n",
                "        train_idx = np.concatenate([indices[:val_start], indices[val_end:]])\n",
                "        \n",
                "        X_train_fold, Y_train_fold = X[train_idx], Y[train_idx]\n",
                "        X_val_fold, Y_val_fold = X[val_idx], Y[val_idx]\n",
                "        \n",
                "        # Linear models need intercept added explicitly here\n",
                "        X_train_int = add_intercept(X_train_fold)\n",
                "        X_val_int = add_intercept(X_val_fold)\n",
                "        \n",
                "        if model_type == 'linear':\n",
                "            W = train_linear_regression(X_train_int, Y_train_fold)\n",
                "        else:\n",
                "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
                "        \n",
                "        Y_pred = predict_linear(X_val_int, W)\n",
                "        \n",
                "        mse_val = mse(Y_val_fold, Y_pred)\n",
                "        r2_val = r2_score(Y_val_fold, Y_pred)\n",
                "        \n",
                "        mse_scores.append(mse_val)\n",
                "        r2_scores.append(r2_val)\n",
                "        \n",
                "    return np.mean(mse_scores), np.mean(r2_scores)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Final Evaluation\n",
                "\n",
                "We train the final models on the **Entire Training Set (80%)** using the optimal hyperparameters found for Lasso, and evaluate them on the **Independent Test Set (20%)**.\n",
                "\n",
                "Metrics used:\n",
                "\n",
                "1.  **Mean Squared Error (MSE)** - The primary loss function:\n",
                "    $$ \\text{MSE} = \\frac{1}{n_{test}} \\sum_{i=1}^{n_{test}} (y_i - \\hat{y}_i)^2 $$\n",
                "\n",
                "2.  **Coefficient of Determination ($R^2$ Score)** - Measures the proportion of variance in the dependent variable that is predictable from the independent variables:\n",
                "    $$ R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2} $$\n",
                "    *   $R^2 = 1$: Perfect prediction.\n",
                "    *   $R^2 = 0$: The model is only as good as predicting the mean ($\\bar{y}$).\n",
                "    *   $R^2 < 0$: The model performs worse than a simple horizontal line (mean).\n",
                "\n",
                "3.  **RMSE (Original Scale)**: The square root of MSE, calculated after transforming the target variable back to its original scale ($e^y - 1$). This provides interpretability in the original unit ($ USD)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model           MSE (Log)       R2 Score  \n",
                        "----------------------------------------\n",
                        "OLS (Linear)    0.1874          0.5362    \n"
                    ]
                }
            ],
            "source": [
                "# Train Final Models on Full Training Set\n",
                "X_train_int = add_intercept(X_train_full)\n",
                "X_test_int = add_intercept(X_test_full)\n",
                "\n",
                "# 1. OLS\n",
                "W_ols = train_linear_regression(X_train_int, Y_train)\n",
                "Y_pred_ols = predict_linear(X_test_int, W_ols)\n",
                "\n",
                "# Metrics\n",
                "mse_ols = mse(Y_test, Y_pred_ols)\n",
                "r2_ols = r2_score(Y_test, Y_pred_ols)\n",
                "\n",
                "print(\"{:<15} {:<15} {:<10}\".format(\"Model\", \"MSE (Log)\", \"R2 Score\"))\n",
                "print(\"-\" * 40)\n",
                "print(\"{:<15} {:<15.4f} {:<10.4f}\".format(\"OLS (Linear)\", mse_ols, r2_ols))\n",
                "\n",
                "# RMSE Original Scale Calculation (USD)\n",
                "\n",
                "\n",
                "# Transform back: exp(log_price) - 1\n",
                "Y_test_orig = np.exp(Y_test) - 1\n",
                "Y_pred_orig = np.exp(Y_pred_ols) - 1\n",
                "\n",
                "rmse_price = np.sqrt(mse(Y_test_orig, Y_pred_orig))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Verification: Comparison with Scikit-learn\n",
                "\n",
                "In this final section, we verify the correctness of our custom **NumPy** implementations by comparing them against the industry-standard **Scikit-learn** versions. \n",
                "\n",
                "- We rely on `sklearn.linear_model` for the models.\n",
                "- We continue to use our **custom NumPy metrics** (`mse`, `r2_score`) for evaluation to ensure an apples-to-apples comparison."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=================================================================================\n",
                        "Model      Implementation  MSE (Log)       R2         RMSE (Orig $)  \n",
                        "---------------------------------------------------------------------------\n",
                        "OLS        Custom NumPy    0.1874          0.5362     $77.28          \n",
                        "OLS        Scikit-learn    0.1874          0.5362     $77.28          \n",
                        "---------------------------------------------------------------------------\n",
                        "Lasso      Scikit-learn    0.1874          0.5362     $77.32          \n",
                        "=================================================================================\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.linear_model import LinearRegression, Lasso\n",
                "\n",
                "# 1. Scikit-learn OLS\n",
                "sklearn_ols = LinearRegression()\n",
                "sklearn_ols.fit(X_train_full, Y_train)\n",
                "Y_pred_sklearn_ols = sklearn_ols.predict(X_test_full)\n",
                "\n",
                "mse_sklearn_ols = mse(Y_test, Y_pred_sklearn_ols)\n",
                "r2_sklearn_ols = r2_score(Y_test, Y_pred_sklearn_ols)\n",
                "rmse_sklearn_ols = np.sqrt(mse(np.exp(Y_test)-1, np.exp(Y_pred_sklearn_ols)-1))\n",
                "\n",
                "# 2. Scikit-learn Lasso \n",
                "sklearn_lasso = Lasso(alpha=0.0001)\n",
                "sklearn_lasso.fit(X_train_full, Y_train)\n",
                "Y_pred_sklearn_lasso = sklearn_lasso.predict(X_test_full)\n",
                "\n",
                "mse_sklearn_lasso = mse(Y_test, Y_pred_sklearn_lasso)\n",
                "r2_sklearn_lasso = r2_score(Y_test, Y_pred_sklearn_lasso)\n",
                "rmse_sklearn_lasso = np.sqrt(mse(np.exp(Y_test)-1, np.exp(Y_pred_sklearn_lasso)-1))\n",
                "\n",
                "# Calculate RMSE for Custom models for the table\n",
                "rmse_ols = np.sqrt(mse(np.exp(Y_test)-1, np.exp(Y_pred_ols)-1))\n",
                "\n",
                "print(\"=================================================================================\")\n",
                "print(\"{:<10} {:<15} {:<15} {:<10} {:<15}\".format(\"Model\", \"Implementation\", \"MSE (Log)\", \"R2\", \"RMSE (Orig $)\"))\n",
                "print(\"-\" * 75)\n",
                "\n",
                "print(\"{:<10} {:<15} {:<15.4f} {:<10.4f} ${:<15.2f}\".format(\"OLS\", \"Custom NumPy\", mse_ols, r2_ols, rmse_ols))\n",
                "print(\"{:<10} {:<15} {:<15.4f} {:<10.4f} ${:<15.2f}\".format(\"OLS\", \"Scikit-learn\", mse_sklearn_ols, r2_sklearn_ols, rmse_sklearn_ols))\n",
                "print(\"-\" * 75)\n",
                "print(\"{:<10} {:<15} {:<15.4f} {:<10.4f} ${:<15.2f}\".format(\"Lasso\", \"Scikit-learn\", mse_sklearn_lasso, r2_sklearn_lasso, rmse_sklearn_lasso))\n",
                "print(\"=================================================================================\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "lab02-airbnb-env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
